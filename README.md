#基于微博文本分析的用户画像分析
##目的
由于本次作业数据的局限性，能分析的用户只有时间，微博内容。通过对文本分析的给用户打上标签。

##环境搭建
###数据库
mongodb 3.2.x
下载安装:https://docs.mongodb.com/master/installation/
>
1.如果已经安装，可用mongod -version查看版本
2.想用gui的话可用robomongo，地址:https://robomongo.org/
3.mongodb数据导入导出教程:http://chenzhou123520.iteye.com/blog/1641319


### 开发环境
- 语言： java 1.8
- IDE： Inteilij IDEA 2016.01
- 依赖库：
   - 自然语言处理工具-HanNLP:https://github.com/hankcs/HanLP
   - mongodb driver:https://docs.mongodb.com/ecosystem/drivers/java/



##流程
### 预处理
####简单预处理
1. 原数据csv格式
源文件 data_new.csv， 数据量60W

2. 提取有效属性(id,content,time,user),存入mongodb，之后一条微博信息如下格式如下
  ```json
{
    "id" : 600357,
    "content" : "#上海微整形#你若许我不离不弃，@男神整形医生铭昊 ，我定许你地久天长。花绽流年，芭比眼，鼻综合，自体脂肪填[微笑]充，情事摇曳，今生我愿为你舒展广袖，假体隆胸隆鼻留幽香于袖底，在楼榭上，水岸边，清幽处，倾尽舞步，舞尽岁月娉婷，舞尽流年芳菲。",
    "time" : "2016/3/16 17:45",
    "user" : "qetina"
}
  ```

3. 坏数据清洗
删除无名数据，如现在数据内部有2567条用户名是"#NAME？"，也就是无名用户的删除

4. 相同用户整合
统计出用户的微博集和活动时间集，样例如下
  ```json
{
    "user" : "niglBBy",
    "contents" : [
        "胡歌上海旅游形象大使。四季上海，天天精彩。 .....",
        "谁粉我我立马粉水！ 【原微博】 @Alina童颜-微整形 不要为明天忧虑，因为明天自有明天的忧虑；一天的难处担当就够了。而我们大人整天都强迫孩子去做一些事情。#上海微整形#却从来没有问过他们快乐不快乐，原来真正蒙在鼓里的是我们",
        "来自星星的微博[心] 【原微博】 @Alina童颜-微整形 不要为明天忧虑，因为明天自有明天的忧虑；一天的难处担当就够了。而我们大人整天都强迫孩子去做一些事情。#上海微整形#却从来没有问过他们快乐不快乐，原来真正蒙在鼓里的是我们",
        "胡歌上海旅游形象大使。四季上海，天天精彩。 【原微博】 #晒春游逛上海#樱花、桃花、郁金香、油菜花，看不尽的花；公园、马路、古镇，逛不完的景；青团、烧卖、春笋、刀鱼面，吃不完的美食……还不跟我一起去春游？@乐游上海"
    ],
    "times" : [
        "2016/3/22 10:55",
        "2016/3/22 10:53",
        "2016/3/22 10:52",
        "2016/3/22 10:52"
    ],
    "count" : 4
}
  ```

5. 活跃用户筛选
因为是做用户画像，那些发表数量少的用户无法准确添加标签，所以筛选了在该数据时间段内的发表微博数在10以上的用户，一共9950名用户。
到这一步完成的数据在百度云链接: http://pan.baidu.com/s/1miCORJ6 密码: gzva
**一共9950条数据，如果出现数据爆内存了（自动断了链接），请在import语句最后加上 --batchSize 1,就能导入成功了**

6. 文本分词 （以下均是未完成内容）
提取微博内容中的名词和实体，然后形容词
如果可以的话，要得到每个实体的比重
- topic分词
  ```json
{
    "_id" : ObjectId("5730b94d0450e85a4f3ffc69"),
    "user" : "A__SIQI",
    "keyword" : [
        "额头",
        "单眼皮",
        "下巴",
        "开眼角",
        "微博",
        "医院",
        "上海",
        "时间",
        "江水",
        "苹果",
        "芭比",
        "微整形",
        "无痕"
    ],
    "topic" : [
        "李易峰 宋仲基",
        "南京无锡常州扬州苏州上海微整形",
        "上海微整形",
        "上海整形美容医疗医院",
        "王思聪女友",
        "2016年流行发色",
        "隆鼻",
        "太阳的后裔结局",
        "上海北京西安榆林南昌长沙宝鸡咸阳微整形",
        "上海婚纱照"
    ]
}
  ```

### 基于分析的处理


### 分析维度

根据群体性结果，制定标签，然后再分配的过程。应对需求。

#### 自然属性
显然是无法分析

#### 性格分析
根据形容用词和性格用词的近似度去匹配。领域用词需要自己去调。

#### 兴趣/话题分析
根据名词和领域名词的近似度去匹配。与性格类似。
#### 时间作息分析
时间做了两个模块的分析，第一模块主要是通过时间分析对用户进行相关的特征分析，第二模块则是采用kmeans算法对每个用户的微博时间进行聚类，获取相对频繁发微博的时间。
第一模块：
    1.对时间按小时进行分组，结果如下
        0 : 20662       1 : 19777         2 : 16682
        3 : 11050       4 : 12078         5 : 11803
        6 : 12341       7 : 12493         8 : 10045
        9 : 16163       10 : 23814        11 : 17565
        12 : 13026      13 : 12228        14 : 13172
        15 : 13465      16 : 11409        17 : 11907
        18 : 5346       19 : 6936         20 : 16169
        21 : 14762      22 : 12804        23 : 18198
    最最出乎意料的是3-6竟然那么多微博，大家都不睡觉吗？所以觉得可能是值班无聊或失眠吧。

   2.根据这个统计结果制定相应时间的相应tag
   ps：脑洞实在是开不出来
    23,0,1,2:           "夜猫子"
    3,4,5,6:            "经常值夜班或失眠"
    7,8:                "一般早起喜欢早上刷博"
    9,10,14,15,16,17:   "上班空闲"
    11,12,13:           "习惯午餐或午休刷手机"
    18,19:              "晚餐悠闲"
    20,21,22:           "晚间空闲"

   3.对个体进行时间分析，统计制定的时间区间对应的频数

   4.取至多三个频数最高的相应属性
   ```json
   {
    "_id" : ObjectId("575560fae799915351afa91a"),
    "user" : "-宝---宝-",
    "timeTags" : [
        "经常值夜班或失眠",
        "夜猫子",
        "上班空闲"
    ]
}
```
第二模块：对每个用户进行kmeans聚类分析(K取4)，得到K个簇和K个中心点
    -K个中心点关于相应的簇的时间个数呈降序排列，则非常清楚地可以看出用户主要活跃的时间
```json
{
    "_id" : ObjectId("575560fbe799915351afcfe4"),
    "user" : "---麗--",
    "Cluster" : [
        [
            "15:04",
            "14:46",
            "14:51",
            "14:14",
            "14:00",
            "13:30"
        ],
        [
            "21:29",
            "21:16",
            "21:11",
            "20:55",
            "20:29"
        ],
        [
            "17:04",
            "19:18",
            "19:14",
            "19:04",
            "16:49"
        ],
        [
            "12:09",
            "09:35",
            "09:21",
            "12:00",
            "08:01"
        ]
    ],
    "Average" : [
        "14:24",
        "18:17",
        "10:13",
        "21:04"
    ]
}
```

#### 角色分析
主要考虑到微博上存在较多的转发，所以在角色方面，分析了用户的创作属性，即纯转发，加工转发，原创三种角色。
这个分析比较简单，在微博文本分析中简单地将“转发微博”，“//”，“【原微博】”这些关键词出现在句首的认为是单纯转发，存在这些关键词但非句首，则代表转发中表达了自己的意见，即加工转发，余下的则是原创。
当然并非每个用户存在符合上述条件就获取相对特征，我们采用8-2原则，将群体的前20%看做是对应特征的获取对象。
产生两个json文件记录分析结果：
1.各种类型微博的数量
```json
{
    "_id" : ObjectId("57556ee2e7999157385ddf4d"),
    "user" : "----柠檬皮----",
    "pureRepost" : 4,
    "modiRepost" : 12,
    "origin" : 0
}
```
2.分析得到的tag（一般只有一个，说明这个转发习惯可以反应一定的人物性格）
```json
{
    "_id" : ObjectId("57556ee3e7999157385e062b"),
    "user" : "----柠檬皮----",
    "roleTags" : [
        "加工转发"
    ]
}
```


### 准确度

### 群体性行为和个体性行为差异

### 应用

# 参考链接
如何构建用户画像- 概述 - http://www.woshipm.com/pmd/107919.html
新手如何开始用户画像分析 - https://www.zhihu.com/question/29468464
可视化工具推荐 - https://www.zhihu.com/question/31429786
